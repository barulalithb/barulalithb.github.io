<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lalith Project Page</title>
    <link rel="icon" type="image/svg" href="./svgs/artificial-intelligence.svg">
    <link href="./css/tailwind_style.css" rel="stylesheet">
</head>

<body>
    <header class="py-11">
        <!-- Navbar  -->
    
        <nav
            class="bg-white px-20 py-6 dark:bg-gray-900 fixed w-full z-10 top-0 left-0 border-b border-gray-200 dark:border-gray-600">
            <div class="flex flex-wrap items-center justify-between mx-auto">
                <a href="./index.html" class="flex items-center">
                    <img src="./svgs/artificial-intelligence.svg" class="h-9 mr-3 sm:h-9" alt="Flowbite Logo" />
                    <span
                        class="self-center leading-relaxed tracking-widest text-2xl font-normal font-[Cinzel] whitespace-nowrap dark:text-white">Lalith
                        Bharadwaj Baru</span>
                </a>
                <div class="items-center justify-between hidden w-full md:flex md:w-auto md:order-1" id="navbar-sticky">
                    <ul
                        class="flex flex-col py-4 mt-4 border border-white-100 lg bg-white-50 md:flex-row md:space-x-14 md:mt-0 md:text-base md:font-normal md:border-0 md:bg-white dark:bg-gray-800 md:dark:bg-gray-900 dark:border-gray-700">
                        <li>
                            <a href="./index.html"
                                class="block leading-relaxed tracking-wider font-[sen] text-lg py-1 font-medium text-gray-700 rounded hover:bg-gray-100 md:hover:bg-transparent md:hover:text-cyan-500 md:p-0 md:dark:hover:text-white dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent dark:border-gray-700">About
                                Me</a>
                        </li>
                        <li>
                            <a href="./research.html"
                                class="block leading-relaxed tracking-wider font-[sen] text-lg py-1 font-medium text-gray-700 rounded hover:bg-gray-100 md:hover:bg-transparent md:hover:text-cyan-500 md:p-0 md:dark:hover:text-white dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent dark:border-gray-700">Research</a>
                        </li>
                        <li>
                            <a href="./publication.html"
                                class="block leading-relaxed tracking-wider font-[sen] text-lg py-1 font-medium text-gray-700 rounded hover:bg-gray-100 md:hover:bg-transparent md:hover:text-cyan-500 md:p-0 md:dark:hover:text-white dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent dark:border-gray-700">Publications</a>
                        </li>
                        <li>
                            <a href="./teaching_and_more.html"
                                class="block leading-relaxed tracking-wider font-[sen] text-lg py-1 font-medium text-gray-700 rounded hover:bg-gray-100 md:hover:bg-transparent md:hover:text-cyan-500 md:p-0 md:dark:hover:text-white dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent dark:border-gray-700">Teaching
                                and More</a>
                        </li>
                        <li>
                            <a href="./cv.html"
                                class="block leading-relaxed tracking-wider font-[sen] text-lg py-1 font-medium text-gray-700 rounded hover:bg-gray-100 md:hover:bg-transparent md:hover:text-cyan-500 md:p-0 md:dark:hover:text-white dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent dark:border-gray-700">CV</a>
                        </li>
                        <li>
                            <a href="./contact.html"
                                class="block leading-relaxed tracking-wider font-[sen] text-lg py-1 font-medium text-gray-700 rounded hover:bg-gray-100 md:hover:bg-transparent md:hover:text-cyan-500 md:p-0 md:dark:hover:text-white dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent dark:border-gray-700">Contact</a>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>

    <main class="flex flex-row flex-wrap mt-20 px-16">
        <!-- items-center -->
        <div class="container mx-auto">
            <div class="flex flex-row justify-center items-center px-28 py-8 overflow-hidden">
                <div class="w-full">
                    <h1
                        class="uppercase text-center align-middle font-[Cinzel] font-semibold tracking-wider text-5xl text-gray-800 md:text-5xl">
                        Research at IIIT-H</h1>
                </div>

            </div>
        </div>

        <div class="container mx-auto px-8">
            <div class="flex flex-col flex-wrap justify-center items-center px-[20%] mr-1 ml-1 mt-0.5">

                <div>
                    <p
                        class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                        At IIIT-H, I work as Research Fellow at the HAI (Healthcare and Artificial Intelligence)
                        vertical under the guidance of prof. Bapi S Raju <a href="https://www.iiit.ac.in/people/faculty/Bapiraju/" class="font-medium text-blue-600 dark:text-blue-500 hover:underline">(link)</a>. I enjoy designing computational models
                        that aid clinicians with quick and accurate solutions. I have dedicated my time to two major
                        tasks.
                    </p>
                </div>

                <div>
                    <ol class="list-decimal list-inside">
                        <li
                        class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                        Designing a self-supervised contrastive model to acquire histopathological whole slide images.
                        </li>
                        <li
                        class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                        Analyzing various orofacial representations for neurodegenerative diseases such as ALS
                        (Amyotrophic Lateral Sclerosis) and Stroke
                    </li>
                </ol>
                </div>

                <div class="mt-2">
                    <p
                        class="mt-2 mb-6 font-[sen] uppercase text-center text-xl font-bold text-gray-800">
                        Histopathological Analysis
                    </p>
                    
                    <p
                        class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                        Technological advancements have aided clinicians by developing pathological tool kits for
                        cancerous histological data. The visual examination of histopathology slides is one of the prime
                        methods to inspect the prognosis of a tumor based on its morphological appearance. This process
                        is time-consuming and needs a detailed evaluation from the high-resolution whole slide images
                        (WSI's). Hence, we provide a decision support system using deep learning, which in turn analyses
                        and interprets the tumorous regions from the WSI's. The existing literature focuses on cancers
                        with high mortality rates, such as lung, colorectal, and liver. But, we instead focus on
                        cancerous regions that are rare but have high mortality rates, such as the palate, small
                        intestine, and meninges.
                    </p>
                    <p
                        class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                        The existing deep learning algorithms provide explainable neural networks which locate the
                        cancerous proportions in WSI's. But, the erstwhile literature does not provide valid
                        justification regarding the representational structure of deep neural networks. As a result, we
                        acquired a strategy, CKA, which would aid us in comprehending various internal aspects of neural
                        networks.
                    </p>
                    <p
                        class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                        It is well established in the literature that histopathological slide (diagnostic slide) images
                        are one of the gold-standard techniques to analyze and assess cancerous regions and aid
                        clinicians in predicting tumorous profiles. Specifically, developing technological tools can aid
                        clinicians in analyzing the effectiveness of tumors. TCGA <a href="https://portal.gdc.cancer.gov/" class="font-medium text-blue-600 dark:text-blue-500 hover:underline">https://portal.gdc.cancer.gov/</a>. study
                        led to the establishment of massive archives of digital H & E WSI's of Carcinomas. These photos
                        were captured at 20x and 40x magnifications and are nearly Gigapixels, which are visually
                        challenging to examine and evaluate properly.
                    </p>
                </div>


                <div class="mt-2 mb-2 flex items-center justify-center">
                    <img src="./Images/Method.jpg" alt="image description">
                </div>

                <p
                    class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                    This work utilizes self-supervised (label-free) methods to extract representations and provide
                    on-par performance with supervised approaches. This work is still in progress, and the publications
                    and information regarding this work will be added soon.
                </p>


                <div class="mt-2">
                    <p
                        class="mt-2 mb-6 font-[sen] uppercase text-center text-xl font-bold text-gray-800">
                        Analyzing Orofcaial Distortions
                    </p>

                    <p
                        class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                        Currently, neurodegenerative diseases are threatening with their severe implications and the
                        perplexity in their diagnosis. Neurodegenerative diseases are very uncommon, and they are hard
                        to comprehend and diagnose. Hence it is crucial to detect the specified variant of
                        neurodegenerative disease and provide the appropriate remedy immediately. Some of these variants
                        grow progressively, and others act momentarily, making the diagnosis challenging. Large publicly
                        available datasets with facial videos, photos, and clinical information are necessary to improve
                        the effectiveness of Face Recognition systems to encourage their application in clinical
                        practice.
                    </p>
                    <p
                        class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                        The role of Artificial Intelligence in clinical decision-making has played a crucial role in
                        providing cost-efficient and robust throughput. Computer vision methods have significantly
                        progressed in various Face Recognition systems. Hence, we pick a publicly available dataset,
                        i.e., Toronto NeuroFace, which sheds light on developing unique and intelligent deep neural
                        networks for automatically assessing motor speech problems and oro-facial deficits.
                    </p>
                    <p
                        class="mt-1 mb-4 font-[Garamond] font-medium text-justify leading-relaxed text-xl text-gray-900">
                        The details of the Toronto Neuroface data, i.e., subjected explicitly to the participants, data
                        collection procedures, clinical evaluation of the videos, and underlying details of manual
                        annotation of facial landmarks on a subset of frames are vividly illustrated in work
                        <a href="https://slp.utoronto.ca/faculty/yana-yunusova/speech-production-lab/datasets/" class="font-medium text-blue-600 dark:text-blue-500 hover:underline">https://slp.utoronto.ca/faculty/yana-yunusova/speech-production-lab/datasets/</a>
                        </br>
                        This work is still in progress, and the publications and information regarding this work will be
                        added soon.

                    </p>
                </div>


            </div>
        </div>


        <div class="mb-4 mt-4"> </div>


    </main>



    <footer
        class="px-4 mt-6 mb-6 mx-20 bg-white flex-col md:flex md:items-center md:justify-center md:p-6 dark:bg-white">

        <div class="flex justify-center mb-6">

            <div class="mr-2 ml-3">
                <a href="https://github.com/barulalithb"
                    class="text-gray-500 hover:text-gray-900 dark:hover:text-gray-900">
                    <svg class="w-9 h-9" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true">
                        <path fill-rule="evenodd"
                            d="M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0022 12.017C22 6.484 17.522 2 12 2z"
                            clip-rule="evenodd" />
                    </svg>
                    <span class="sr-only">GitHub account</span>
                </a>
            </div>

            <div class="mr-2 ml-3">
                <a href="#" class="text-gray-500 hover:text-gray-900 dark:hover:text-gray-900">
                    <svg class="w-9 h-9" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true">
                        <path
                            d="M8.29 20.251c7.547 0 11.675-6.253 11.675-11.675 0-.178 0-.355-.012-.53A8.348 8.348 0 0022 5.92a8.19 8.19 0 01-2.357.646 4.118 4.118 0 001.804-2.27 8.224 8.224 0 01-2.605.996 4.107 4.107 0 00-6.993 3.743 11.65 11.65 0 01-8.457-4.287 4.106 4.106 0 001.27 5.477A4.072 4.072 0 012.8 9.713v.052a4.105 4.105 0 003.292 4.022 4.095 4.095 0 01-1.853.07 4.108 4.108 0 003.834 2.85A8.233 8.233 0 012 18.407a11.616 11.616 0 006.29 1.84" />
                    </svg>
                    <span class="sr-only">Twitter page</span>
                </a>
            </div>

            <div class="mr-2 ml-3">
                <a href="#" class="text-gray-500 hover:text-gray-900 dark:hover:text-gray-900">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-9 h-9">
                        <path
                            d="M3 4a2 2 0 00-2 2v1.161l8.441 4.221a1.25 1.25 0 001.118 0L19 7.162V6a2 2 0 00-2-2H3z" />
                        <path
                            d="M19 8.839l-7.77 3.885a2.75 2.75 0 01-2.46 0L1 8.839V14a2 2 0 002 2h14a2 2 0 002-2V8.839z" />
                    </svg>
                    <span class="sr-only">Email</span>
                </a>
            </div>

        </div>

        <span class="text-base font-medium text-black-400 sm:text-center dark:text-black-400">© 2022 <a href="#"
                class="hover:underline">Lalith Bharadwaj™</a>. All Rights Reserved.
        </span>
    </footer>

</body>

</html>